{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"logos/‎cover‎001.png\" alt=\"Drawing\"/>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyxdf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Latency tests\n",
    "Situation:\n",
    "We designed a virtual environment in Unity that indefinitely switches the color of a canvas from black -> white -> gray -> black. The test files with different durations are stored in the folder \"data\". Before loading them, we want to access their path and save them in a dictionary.\n",
    "\n",
    "### Task 1:\n",
    "- Get all files from \"data\" folder, sort them alphabetically and save them to a variable \"files\"\n",
    "Hint: os.listdir()\n",
    "Desired output: ['lsl_test1.xdf', 'lsl_test2.xdf', 'lsl_test3.xdf']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get all files from the folder \"data\"\n",
    "files =\n",
    "# sort them alphabetically\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# save all files to an empty dictionary \"recordings\"\n",
    "recordings = {}\n",
    "\n",
    "for i, file in enumerate(files):  # store and display all files\n",
    "    created = os.path.getmtime(f\"data/{file}\")  # creation timestamp\n",
    "    created = datetime.datetime.fromtimestamp(created)  # translate as datetime\n",
    "    created = created.strftime(\"%d.%m.%Y %H:%M\")  # arrange it\n",
    "    recordings[i] = {\"file\": file, \"created\": created}\n",
    "\n",
    "files = [f.split(\".\")[0] for f in files]\n",
    "# display the recordings and metadata\n",
    "display(recordings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extensible Data Format (XDF)\n",
    "\n",
    ".XDF is a format to store multiple channels of time series data with specific meta information.\n",
    "For the latency test, we stored three streams\n",
    "- Unity: 'Visual',\n",
    "- EEG: 'openvibeMarkers', 'openvibeSignal'\n",
    "\n",
    "When loaded, the .XDF file results in a list of dictionaries with some components:\n",
    "1. **'info':**\n",
    "2. **'time_series':** the information sent from Unity and EEG to via LSL\n",
    "3. **'time_stamps':** the time stamps for each datapoint received"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2:\n",
    "Load data for recording one in a variable _streams_ and have a look at structure.\n",
    "<strong>Hint:</strong>  for more information on how to load and what is actually loaded from .XDF, visit [.XDF website info](https://pypi.org/project/pyxdf/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accessing streams\n",
    "Once we load the streams, we can access each list in the dictionary by indicating, for example, the component we want to access such as a specific stream recorded (an index), 'info', 'time_stamps', 'time_series', etc.\n",
    "For specific information:\n",
    "- streams[2]['info']['name']\n",
    "\n",
    "For a particular stream component:\n",
    "- streams[2]['time_stamps']\n",
    "\n",
    "For a specific eeg channel\n",
    "- streams[2][\"time_series\"][:,64]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# access the second stream's time_stamps\n",
    "streams[2]['time_stamps']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# acess all stream names and index in stream list\n",
    "s_names = {streams[i][\"info\"][\"name\"][0]: i for i in range(len(streams))}\n",
    "s_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 3: Defining functions\n",
    "\n",
    "<strong>Function 1</strong>\n",
    "Define a function that given the .xdf streams, returns the relevant streams we recorded:\n",
    "- The Unity samples were sent via a stream called _Visual_\n",
    "- The EEG light sensor data was sent via a stream called _openvibeSignal_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define a function to select \"Visual streams  and openvibeSignal from streams\n",
    "def select_streams(streams):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# use the function to select the Unity ('u_ch') and EEG ('e_ch') streams\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 2</strong>\n",
    "\n",
    "Define a function that returns the computer \"hostname\" from the \"info\" dictionary given the streams data and the selected streams"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# retrieve computer hostname\n",
    "def stream_host(streams, u_ch, e_ch):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 3</strong>\n",
    "\n",
    "Define a function that returns the \"time_stamps\" for each selected stream in the streams' data.\n",
    "\n",
    "Notice that LSL assigns a random large number at the start of the recording to both EEG and Unity to synchronize them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# retrieve Unity ('u') and EEG ('e') time stamps\n",
    "def streams_ts(streams, u_ch, e_ch):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 4</strong>\n",
    "\n",
    "Define a function that corrects the Unity and EEG timestamps to start at zero\n",
    "\n",
    "<strong>Hint:</strong>  return a numpy array containing all corrected timestamps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# correct Unity ('u') and EEG ('e') time stamps to start at 0\n",
    "def corrected_ts(time_stamps):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 5</strong>\n",
    "\n",
    "Define a function that calculates the latency of one sample to the next using the normalized timestamps.\n",
    "\n",
    "<strong>Hint:</strong> latency defined as the time difference between a timestamp and the next one"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate the latency between one sample and the next\n",
    "def calculate_latency(ts_norm):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 6</strong>\n",
    "\n",
    "Define a function that retrieves the EEG and Unity streams data stored in _\"time_series\"_\n",
    "Hint: \"time_series\" contains the data sample that corresponds to each timestamp.\n",
    "\n",
    "For Unity, we saved 0, 1, and 2 every time it switched from black to gray to white (channel 1)\n",
    "EEG contains the changes in light intensity for each of the colors collected in channel 64"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# retrieve Unity ('u') and EEG ('e') stream data\n",
    "def streams_data(streams, u_ch, e_ch):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 7</strong>\n",
    "\n",
    "Define a function that calculates the test duration in minutes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate recording's duration\n",
    "def test_duration(time_stamps):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<strong>Function 8</strong>\n",
    "\n",
    "Define a function that calculates the average sampling rate\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate sampling rate (fps)\n",
    "def sampling_fps(t_duration, time_stamps):\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Access all tests data\n",
    "\n",
    "Now we can use the above functions to iterate over all the recordings and retrieve the corresponding data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract streams info for all files\n",
    "overview_df = pd.DataFrame()\n",
    "recordings_data_eeg = pd.DataFrame()\n",
    "recordings_data_unity = pd.DataFrame()\n",
    "\n",
    "for r in recordings:\n",
    "    # current filename\n",
    "    file = recordings[r][\"file\"]\n",
    "    # load data\n",
    "    streams, _ = pyxdf.load_xdf(f\"data/{file}\")\n",
    "    # select stream channels\n",
    "    u_ch, e_ch = select_streams(streams)\n",
    "    # computer host name\n",
    "    u_host, e_host = stream_host(streams, u_ch, e_ch)\n",
    "    # select timestamps for each stream\n",
    "    u_ts, e_ts = streams_ts(streams, u_ch, e_ch)\n",
    "    # corrected timestamps to start at zero\n",
    "    u_ts_corrected = corrected_ts(u_ts)\n",
    "    e_ts_corrected = corrected_ts(e_ts)\n",
    "    # latency of normalized timestamps\n",
    "    u_latency = calculate_latency(u_ts_corrected)\n",
    "    e_latency = calculate_latency(e_ts_corrected)\n",
    "    # samples data from streams\n",
    "    u_data, e_data = streams_data(streams, u_ch, e_ch)\n",
    "    # calculate Unity - eeg time difference at start of recording\n",
    "    # in milliseconds\n",
    "    diff_ts = (u_ts[0] - e_ts[0]) * 1000\n",
    "    # calculate recoding duration\n",
    "    unity_duration =  test_duration(u_ts)\n",
    "    eeg_duration =  test_duration(e_ts)\n",
    "    # calculate sampling rate (FPS)\n",
    "    unity_sr = sampling_fps(unity_duration, u_ts)\n",
    "    eeg_sr = sampling_fps(eeg_duration, e_ts)\n",
    "    # Store overview statistics for each test\n",
    "    overview_df = pd.concat([overview_df, pd.DataFrame.from_dict({\"file_name\": file,\n",
    "                         \"u_duration\": unity_duration,\n",
    "                         \"diff_ts\": diff_ts,\n",
    "                         \"eeg_duration\": eeg_duration,\n",
    "                         \"u_fps\": unity_sr,\n",
    "                         \"eeg_fps\": eeg_sr,\n",
    "                         \"u_host\": u_host,\n",
    "                         \"eeg_host\": e_host})])\n",
    "    # Store key stream for use in analysis\n",
    "    recording_data_eeg = pd.concat([pd.DataFrame(np.resize(file, len(e_ts_corrected)), columns=['filename']),\n",
    "                               pd.DataFrame(e_ts, columns=['e_ts']),\n",
    "                               pd.DataFrame(e_ts_corrected, columns=['e_ts_corrected']),\n",
    "                               pd.DataFrame(e_latency, columns=['e_latency']),\n",
    "                               pd.DataFrame(e_data, columns=['sensor_data'])], axis=1)\n",
    "    recording_data_unity = pd.concat([pd.DataFrame(np.resize(file, len(u_ts_corrected)), columns=['filename']),\n",
    "                               pd.DataFrame(u_ts, columns=['u_ts']),\n",
    "                               pd.DataFrame(u_ts_corrected, columns=['u_ts_corrected']),\n",
    "                               pd.DataFrame(u_latency, columns=['u_latency']),\n",
    "                               pd.DataFrame(u_data, columns=['switch_state'])], axis=1)\n",
    "    recordings_data_eeg = pd.concat([recordings_data_eeg, recording_data_eeg])\n",
    "    recordings_data_unity = pd.concat([recordings_data_unity, recording_data_unity])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preview recordings' information\n",
    "overview_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preview of Unity data\n",
    "recordings_data_unity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preview EEG data\n",
    "recordings_data_eeg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tests' descriptive statistic\n",
    "Now we can calculate the average latency with which each Unity and EEG sample entered the system for each of the recorded tests.\n",
    "\n",
    "### Task 4:\n",
    "- Calculate the average latency for each device (EEG, Unity)\n",
    "- How constant are the frame rates?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unity's latency\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# EEG's latency\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Latencies visualization\n",
    "### Task 5:\n",
    "- Visualize the latencies distributions for EEG and Unity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start latencies figure/subplots here\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Markers' visualizations\n",
    "Now we will visualize the behavior between EEG and Unity for the first 5 seconds of recording in one of the tests.\n",
    "### Task 6:\n",
    "- Select test number 3 from the Unity and EEG dataframe and visualize the first 5 seconds of recording"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Unity's first 5 seconds\n",
    "\n",
    "# EEG's first 5 seconds\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# start recording figure/subplots here\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusions:\n",
    "1. EEG sampling rate was extremely constant with each sample latency (mean = ~ 0.98 ms, std = 0.0)\n",
    "2. Unity sampling rate was constant with each sample latency (mean = ~ 11.11 ms, std = 0.75 ms)\n",
    "3. Latencies for both devices were constant independently of recording duration\n",
    "4. <strong>LSL is a reliable method to collect brain and behavioral data when combining EEG and VR.</strong>"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
